{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 15:39:45.387821: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-22 15:39:45.387877: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-22 15:39:45.389070: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-22 15:39:45.396170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding, Bidirectional, LSTM, Flatten, GlobalMaxPool1D, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>sentiment_scores</th>\n",
       "      <th>word2vec_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>sadness</td>\n",
       "      <td>['DET', 'NOUN', 'VERB', 'PUNCT']</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.5267</td>\n",
       "      <td>[ 0.05542755  0.07275391  0.0168457   0.033126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldnâ€™t be a grouping category I...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>['SPACE', 'X', 'NOUN', 'AUX', 'PART', 'AUX', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[-3.86629972e-02  2.17396129e-02  1.77334872e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>['PRON', 'VERB', 'ADV', 'PUNCT', 'SCONJ', 'PRO...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>[ 1.75781250e-02 -2.71402989e-02  1.20768227e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>happiness</td>\n",
       "      <td>['INTJ', 'PRON', 'VERB', 'NOUN', 'PUNCT']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>[ 0.17626953 -0.04703776  0.00406901  0.087239...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>['X', 'NOUN', 'PUNCT', 'AUX', 'ADV', 'ADP', 'P...</td>\n",
       "      <td>['Falcon']</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[ 0.0814209   0.01818848 -0.05981445  0.065185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629491</th>\n",
       "      <td>that was what i felt when i was finally accept...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>['PRON', 'AUX', 'PRON', 'PRON', 'VERB', 'SCONJ...</td>\n",
       "      <td>['a couple of years']</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>[-0.04505539  0.01730728 -0.06948853  0.005584...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629492</th>\n",
       "      <td>i take every day as it comes i m just focussin...</td>\n",
       "      <td>fear</td>\n",
       "      <td>['PRON', 'VERB', 'DET', 'NOUN', 'SCONJ', 'PRON...</td>\n",
       "      <td>['every day']</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>[-0.03127872  0.13306023  0.06667911  0.076911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629493</th>\n",
       "      <td>i just suddenly feel that everything was fake</td>\n",
       "      <td>sadness</td>\n",
       "      <td>['PRON', 'ADV', 'ADV', 'VERB', 'SCONJ', 'PRON'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>[ 1.35253906e-01  9.81140137e-03 -5.22766113e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629494</th>\n",
       "      <td>im feeling more eager than ever to claw back w...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>['PRON', 'AUX', 'VERB', 'ADV', 'ADJ', 'SCONJ',...</td>\n",
       "      <td>['last week']</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>[-0.00286865  0.11989049 -0.0135498   0.046508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629495</th>\n",
       "      <td>i give you plenty of attention even when i fee...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>['PRON', 'VERB', 'PRON', 'NOUN', 'ADP', 'NOUN'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.5413</td>\n",
       "      <td>[ 0.11185128  0.01263428 -0.04787336  0.041665...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629496 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence    emotion  \\\n",
       "0                                         That game hurt.    sadness   \n",
       "1        >sexuality shouldnâ€™t be a grouping category I...  happiness   \n",
       "2          You do right, if you don't care then fuck 'em!    neutral   \n",
       "3                                      Man I love reddit.  happiness   \n",
       "4       [NAME] was nowhere near them, he was by the Fa...    neutral   \n",
       "...                                                   ...        ...   \n",
       "629491  that was what i felt when i was finally accept...  happiness   \n",
       "629492  i take every day as it comes i m just focussin...       fear   \n",
       "629493      i just suddenly feel that everything was fake    sadness   \n",
       "629494  im feeling more eager than ever to claw back w...  happiness   \n",
       "629495  i give you plenty of attention even when i fee...    sadness   \n",
       "\n",
       "                                                 pos_tags  \\\n",
       "0                        ['DET', 'NOUN', 'VERB', 'PUNCT']   \n",
       "1       ['SPACE', 'X', 'NOUN', 'AUX', 'PART', 'AUX', '...   \n",
       "2       ['PRON', 'VERB', 'ADV', 'PUNCT', 'SCONJ', 'PRO...   \n",
       "3               ['INTJ', 'PRON', 'VERB', 'NOUN', 'PUNCT']   \n",
       "4       ['X', 'NOUN', 'PUNCT', 'AUX', 'ADV', 'ADP', 'P...   \n",
       "...                                                   ...   \n",
       "629491  ['PRON', 'AUX', 'PRON', 'PRON', 'VERB', 'SCONJ...   \n",
       "629492  ['PRON', 'VERB', 'DET', 'NOUN', 'SCONJ', 'PRON...   \n",
       "629493  ['PRON', 'ADV', 'ADV', 'VERB', 'SCONJ', 'PRON'...   \n",
       "629494  ['PRON', 'AUX', 'VERB', 'ADV', 'ADJ', 'SCONJ',...   \n",
       "629495  ['PRON', 'VERB', 'PRON', 'NOUN', 'ADP', 'NOUN'...   \n",
       "\n",
       "               named_entities  sentiment_scores  \\\n",
       "0                          []           -0.5267   \n",
       "1                          []            0.0000   \n",
       "2                          []            0.1316   \n",
       "3                          []            0.6369   \n",
       "4                  ['Falcon']            0.0000   \n",
       "...                       ...               ...   \n",
       "629491  ['a couple of years']            0.2732   \n",
       "629492          ['every day']            0.5859   \n",
       "629493                     []           -0.4767   \n",
       "629494          ['last week']            0.5095   \n",
       "629495                     []           -0.5413   \n",
       "\n",
       "                                      word2vec_embeddings  \n",
       "0       [ 0.05542755  0.07275391  0.0168457   0.033126...  \n",
       "1       [-3.86629972e-02  2.17396129e-02  1.77334872e-...  \n",
       "2       [ 1.75781250e-02 -2.71402989e-02  1.20768227e-...  \n",
       "3       [ 0.17626953 -0.04703776  0.00406901  0.087239...  \n",
       "4       [ 0.0814209   0.01818848 -0.05981445  0.065185...  \n",
       "...                                                   ...  \n",
       "629491  [-0.04505539  0.01730728 -0.06948853  0.005584...  \n",
       "629492  [-0.03127872  0.13306023  0.06667911  0.076911...  \n",
       "629493  [ 1.35253906e-01  9.81140137e-03 -5.22766113e-...  \n",
       "629494  [-0.00286865  0.11989049 -0.0135498   0.046508...  \n",
       "629495  [ 0.11185128  0.01263428 -0.04787336  0.041665...  \n",
       "\n",
       "[629496 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv') # My dataset\n",
    "\n",
    "train # Display the first 5 rows of the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "happiness    258682\n",
       "sadness      135826\n",
       "anger         86327\n",
       "neutral       55898\n",
       "fear          51226\n",
       "surprise      31486\n",
       "disgust       10051\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>sentiment_scores</th>\n",
       "      <th>word2vec_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>sadness</td>\n",
       "      <td>['DET', 'NOUN', 'VERB', 'PUNCT']</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.5267</td>\n",
       "      <td>[ 0.05542755  0.07275391  0.0168457   0.033126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>['PRON', 'VERB', 'ADV', 'PUNCT', 'SCONJ', 'PRO...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>[ 1.75781250e-02 -2.71402989e-02  1.20768227e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>['X', 'NOUN', 'PUNCT', 'AUX', 'ADV', 'ADP', 'P...</td>\n",
       "      <td>['Falcon']</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[ 0.0814209   0.01818848 -0.05981445  0.065185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He isn't as big, but he's still quite popular....</td>\n",
       "      <td>anger</td>\n",
       "      <td>['PRON', 'AUX', 'PART', 'ADV', 'ADJ', 'PUNCT',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.6297</td>\n",
       "      <td>[ 1.14733890e-01  4.03053276e-02  2.13256832e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have, and now that you mention it, I think t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>['PRON', 'VERB', 'PUNCT', 'CCONJ', 'ADV', 'SCO...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[ 0.09745789  0.00759125  0.07655334  0.148986...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  emotion  \\\n",
       "0                                    That game hurt.  sadness   \n",
       "1     You do right, if you don't care then fuck 'em!  neutral   \n",
       "2  [NAME] was nowhere near them, he was by the Fa...  neutral   \n",
       "3  He isn't as big, but he's still quite popular....    anger   \n",
       "4  I have, and now that you mention it, I think t...  neutral   \n",
       "\n",
       "                                            pos_tags named_entities  \\\n",
       "0                   ['DET', 'NOUN', 'VERB', 'PUNCT']             []   \n",
       "1  ['PRON', 'VERB', 'ADV', 'PUNCT', 'SCONJ', 'PRO...             []   \n",
       "2  ['X', 'NOUN', 'PUNCT', 'AUX', 'ADV', 'ADP', 'P...     ['Falcon']   \n",
       "3  ['PRON', 'AUX', 'PART', 'ADV', 'ADJ', 'PUNCT',...             []   \n",
       "4  ['PRON', 'VERB', 'PUNCT', 'CCONJ', 'ADV', 'SCO...             []   \n",
       "\n",
       "   sentiment_scores                                word2vec_embeddings  \n",
       "0           -0.5267  [ 0.05542755  0.07275391  0.0168457   0.033126...  \n",
       "1            0.1316  [ 1.75781250e-02 -2.71402989e-02  1.20768227e-...  \n",
       "2            0.0000  [ 0.0814209   0.01818848 -0.05981445  0.065185...  \n",
       "3            0.6297  [ 1.14733890e-01  4.03053276e-02  2.13256832e-...  \n",
       "4            0.0000  [ 0.09745789  0.00759125  0.07655334  0.148986...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the first 200k happiness emotions in the emotion column\n",
    "train = train.drop(train[train['emotion'] == 'happiness'].index[:100000])\n",
    "\n",
    "# Reset the index\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "# Display the first 5 rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "happiness    158682\n",
       "sadness      135826\n",
       "anger         86327\n",
       "neutral       55898\n",
       "fear          51226\n",
       "surprise      31486\n",
       "disgust       10051\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount of emotions in emotion column\n",
    "train['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Girls are happy when they get flowers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>His jaw dropped in disbelief when he saw the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sometimes the ugly stench makes me wanna throw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The foul odor from the garbage bin was disgust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I canâ€™t believe it, they lost the game in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence\n",
       "0   0              Girls are happy when they get flowers\n",
       "1   1  His jaw dropped in disbelief when he saw the p...\n",
       "2   2  Sometimes the ugly stench makes me wanna throw...\n",
       "3   3  The foul odor from the garbage bin was disgust...\n",
       "4   4  I canâ€™t believe it, they lost the game in the ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv', sep='\\t')\n",
    "\n",
    "test.head() #Display the first 5 rows of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize the sentences in the test dataset\n",
    "test_sequences = tokenizer.texts_to_sequences(test['sentence'])\n",
    "\n",
    "# # Pad the sequences to ensure uniform length\n",
    "X_test = pad_sequences(test_sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train['sentence'].values\n",
    "train_labels = train['emotion'].values\n",
    "test_sentences = test['sentence'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "train_labels_one_hot = tf.keras.utils.to_categorical(train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentences\n",
    "tokenizer = Tokenizer(oov_token='<OOV>', num_words=10000000)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "tokenizer.fit_on_texts(test_sentences)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences for training data\n",
    "max_length = max(len(x) for x in train_sequences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Pad sequences for testing data using the same max_length\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_padded, train_labels_one_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique emotions: ['sadness' 'neutral' 'anger' 'surprise' 'disgust' 'fear' 'happiness']\n",
      "Number of unique emotions: 7\n"
     ]
    }
   ],
   "source": [
    "unique_emotions = train['emotion'].unique()\n",
    "num_emotions = len(unique_emotions)\n",
    "print(\"Unique emotions:\", unique_emotions)\n",
    "print(\"Number of unique emotions:\", num_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 15:40:28.633911: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-03-22 15:40:28.634230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14943 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 178, 400)          33470800  \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 178, 1032)         3785376   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 178, 256)          264448    \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 256)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37562231 (143.29 MB)\n",
      "Trainable params: 37562231 (143.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size\n",
    "embedding_dim = 64  # Dimensionality of the embedding layer\n",
    "num_emotions = len(unique_emotions)  # Number of unique emotions\n",
    "\n",
    "# Defining the RNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=400, input_length=178),  # Increased embedding dimension\n",
    "    Bidirectional(LSTM(516, return_sequences=True)),  # Adjusted LSTM units\n",
    "    # Dropout(0.5),  # Added dropout for regularization\n",
    "    Dense(256, activation='relu'),\n",
    "    GlobalMaxPool1D(),  # Global max pooling\n",
    "    Dense(128, activation='relu'),  # Adjusted Dense layer units\n",
    "    Dense(64, activation='relu'),\n",
    "    # Dropout(0.5),  # Added dropout for regularization\n",
    "    Dense(num_emotions, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "model.summary() # Display the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    # Calculate Precision and Recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=[f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 15:40:33.039791: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "2024-03-22 15:40:33.640077: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ef2084b9370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-22 15:40:33.640116: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2024-03-22 15:40:33.645651: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711122033.777090  100453 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3310/3310 [==============================] - 341s 101ms/step - loss: 0.4293 - f1_score: 0.8263 - val_loss: 0.3586 - val_f1_score: 0.8575\n",
      "Epoch 2/10\n",
      "3310/3310 [==============================] - 298s 90ms/step - loss: 0.3343 - f1_score: 0.8671 - val_loss: 0.3472 - val_f1_score: 0.8607\n",
      "Epoch 3/10\n",
      "3310/3310 [==============================] - 286s 86ms/step - loss: 0.3045 - f1_score: 0.8765 - val_loss: 0.3547 - val_f1_score: 0.8634\n",
      "Epoch 4/10\n",
      "3310/3310 [==============================] - 203s 61ms/step - loss: 0.2810 - f1_score: 0.8824 - val_loss: 0.3687 - val_f1_score: 0.8605\n",
      "Epoch 5/10\n",
      "3310/3310 [==============================] - 204s 62ms/step - loss: 0.2610 - f1_score: 0.8870 - val_loss: 0.4005 - val_f1_score: 0.8584\n",
      "Epoch 6/10\n",
      "3310/3310 [==============================] - 199s 60ms/step - loss: 0.2450 - f1_score: 0.8901 - val_loss: 0.4301 - val_f1_score: 0.8601\n",
      "Epoch 7/10\n",
      "3310/3310 [==============================] - 198s 60ms/step - loss: 0.2314 - f1_score: 0.8928 - val_loss: 0.4439 - val_f1_score: 0.8606\n"
     ]
    }
   ],
   "source": [
    "# Training the model with early stopping\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=128, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1, \n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105900 105900\n"
     ]
    }
   ],
   "source": [
    "print(len(X_val), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict(X_val) # For confusion matrix\n",
    "y_pred = model.predict(test_padded) # For Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to label indices\n",
    "predicted_class_indices = np.argmax(y_pred, axis=1)\n",
    "true_classes = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Use the LabelEncoder to decode the predictions to original labels\n",
    "predicted_emotions = label_encoder.inverse_transform(predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [105900, 1436]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Compute confusion matrix\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_class_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Normalize the confusion matrix\u001b[39;00m\n\u001b[1;32m      9\u001b[0m cm_normalized \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m cm\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:319\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    225\u001b[0m     {\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [105900, 1436]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_class_indices)\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt=\".2%\", cmap=\"Blues\", xticklabels=unique_emotions, yticklabels=unique_emotions)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Emotion\")\n",
    "plt.ylabel(\"True Emotion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to my test dataset\n",
    "test['emotion'] = predicted_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Girls are happy when they get flowers</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>His jaw dropped in disbelief when he saw the p...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sometimes the ugly stench makes me wanna throw...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The foul odor from the garbage bin was disgust...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I canâ€™t believe it, they lost the game in the ...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence   emotion\n",
       "0   0              Girls are happy when they get flowers   neutral\n",
       "1   1  His jaw dropped in disbelief when he saw the p...   neutral\n",
       "2   2  Sometimes the ugly stench makes me wanna throw...     anger\n",
       "3   3  The foul odor from the garbage bin was disgust...   disgust\n",
       "4   4  I canâ€™t believe it, they lost the game in the ...  surprise"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   emotion\n",
       "0   0   neutral\n",
       "1   1   neutral\n",
       "2   2     anger\n",
       "3   3   disgust\n",
       "4   4  surprise"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop sentence column\n",
    "test = test.drop(columns=['sentence'])\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('rnn_model_yuliia.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
